{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrR3vHKMKBvs"
   },
   "source": [
    "# Подключение основных библиотек и загрузка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I191QjG8KXuc"
   },
   "source": [
    "### Для Google Colaboratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qy8_YnUIKUtP",
    "outputId": "489eb2c1-9104-45cf-aba8-741d532311a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Подключение Google Drive к виртуальной машине\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Копирование данных с Google Drive на локальный диск виртуальной машины.\n",
    "!cp -r /content/drive/MyDrive/practice_2022-2023/data/ICBEBnpy/ .\n",
    "#!cp -r /content/drive/MyDrive/practice_2022-2023/data/ptbxlnpy/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69I1ojW9SmvR"
   },
   "source": [
    "### Подключение пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mnJksOuYBEbl"
   },
   "outputs": [],
   "source": [
    "# Для работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "import seaborn as sns   # plotting heatmap\n",
    "\n",
    "# Для работы с моделями\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "# Для метрик\n",
    "from keras import backend as K\n",
    "from keras.metrics import AUC, Recall, Precision, Accuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# Функции\n",
    "# Загрузка ICBEB\n",
    "def load_ICBEB(task):\n",
    "  if task == 'diag':\n",
    "    X_train = np.load('ICBEBnpy/X_train_ICBEB_diag.npy')\n",
    "    y_train = np.load('ICBEBnpy/y_train_ICBEB_diag.npy')\n",
    "    X_test = np.load('ICBEBnpy/X_val_ICBEB_diag.npy')\n",
    "    y_test = np.load('ICBEBnpy/y_val_ICBEB_diag.npy')\n",
    "  elif task == 'superdiag':\n",
    "    X_train = np.load('ICBEBnpy/X_train_ICBEB_superdiag.npy')\n",
    "    y_train = np.load('ICBEBnpy/y_train_ICBEB_superdiag.npy')\n",
    "    X_test = np.load('ICBEBnpy/X_val_ICBEB_superdiag.npy')\n",
    "    y_test = np.load('ICBEBnpy/y_val_ICBEB_superdiag.npy')\n",
    "  elif task == 'subdiag':\n",
    "    X_train = np.load('ICBEBnpy/X_train_ICBEB_subdiag.npy')\n",
    "    y_train = np.load('ICBEBnpy/y_train_ICBEB_subdiag.npy')\n",
    "    X_test = np.load('ICBEBnpy/X_val_ICBEB_subdiag.npy')\n",
    "    y_test = np.load('ICBEBnpy/y_val_ICBEB_subdiag.npy')\n",
    "  elif task == 'rhythm':\n",
    "    X_train = np.load('ICBEBnpy/X_train_ICBEB_rhythm.npy')\n",
    "    y_train = np.load('ICBEBnpy/y_train_ICBEB_rhythm.npy')\n",
    "    X_test = np.load('ICBEBnpy/X_val_ICBEB_rhythm.npy')\n",
    "    y_test = np.load('ICBEBnpy/y_val_ICBEB_rhythm.npy')\n",
    "  elif task == 'form':\n",
    "    X_train = np.load('ICBEBnpy/X_train_ICBEB_form.npy')\n",
    "    y_train = np.load('ICBEBnpy/y_train_ICBEB_form.npy')\n",
    "    X_test = np.load('ICBEBnpy/X_val_ICBEB_form.npy')\n",
    "    y_test = np.load('ICBEBnpy/y_val_ICBEB_form.npy')\n",
    "  #print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Загрузка ptbxl\n",
    "def load_ptbxl(task):\n",
    "  if task == 'diag':\n",
    "    X_train = np.load('ptbxlnpy/X_train_ptbxl_diag.npy')\n",
    "    y_train = np.load('ptbxlnpy/y_train_ptbxl_diag.npy')\n",
    "    X_test = np.load('ptbxlnpy/X_val_ptbxl_diag.npy')\n",
    "    y_test = np.load('ptbxlnpy/y_val_ptbxl_diag.npy')\n",
    "  elif task == 'superdiag':\n",
    "    X_train = np.load('ptbxlnpy/X_train_ptbxl_superdiag.npy')\n",
    "    y_train = np.load('ptbxlnpy/y_train_ptbxl_superdiag.npy')\n",
    "    X_test = np.load('ptbxlnpy/X_val_ptbxl_superdiag.npy')\n",
    "    y_test = np.load('ptbxlnpy/y_val_ptbxl_superdiag.npy')\n",
    "  elif task == 'subdiag':\n",
    "    X_train = np.load('ptbxlnpy/X_train_ptbxl_subdiag.npy')\n",
    "    y_train = np.load('ptbxlnpy/y_train_ptbxl_subdiag.npy')\n",
    "    X_test = np.load('ptbxlnpy/X_val_ptbxl_subdiag.npy')\n",
    "    y_test = np.load('ptbxlnpy/y_val_ptbxl_subdiag.npy')\n",
    "  elif task == 'rhythm':\n",
    "    X_train = np.load('ptbxlnpy/X_train_ptbxl_rhythm.npy')\n",
    "    y_train = np.load('ptbxlnpy/y_train_ptbxl_rhythm.npy')\n",
    "    X_test = np.load('ptbxlnpy/X_val_ptbxl_rhythm.npy')\n",
    "    y_test = np.load('ptbxlnpy/y_val_ptbxl_rhythm.npy')\n",
    "  elif task == 'form':\n",
    "    X_train = np.load('ptbxlnpy/X_train_ptbxl_form.npy')\n",
    "    y_train = np.load('ptbxlnpy/y_train_ptbxl_form.npy')\n",
    "    X_test = np.load('ptbxlnpy/X_val_ptbxl_form.npy')\n",
    "    y_test = np.load('ptbxlnpy/y_val_ptbxl_form.npy')\n",
    "  #print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "  return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Компиляция и обучение модели\n",
    "def AUC_Keras(y_true, y_pred):\n",
    "    auc = keras.metrics.AUC(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "# Компиляция и обучение модели\n",
    "def compile_fit(model, X_train, y_train, X_val = None, y_val = None, validation_split = 0.0, early_stopping = None, model_checkpoint = None):\n",
    "  model.compile(loss = keras.losses.CategoricalCrossentropy(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=['AUC'])\n",
    "  \n",
    "  if X_val == None:\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs = 30, \n",
    "                        validation_data = None, \n",
    "                        validation_split=validation_split, \n",
    "                        callbacks=[model_checkpoint, early_stopping])\n",
    "  else:\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs = 30, \n",
    "                        validation_data = (X_val, y_val), \n",
    "                        validation_split=0.0, \n",
    "                        callbacks=[model_checkpoint, early_stopping])\n",
    "  return history\n",
    "\n",
    "# TP TN FP FN\n",
    "def tp_tn_fp_fn(y_true, y_pred):\n",
    "  TP = TruePositives()\n",
    "  TN = TrueNegatives()\n",
    "  FP = FalsePositives()\n",
    "  FN = FalseNegatives()\n",
    "  TP.update_state(y_true, y_pred)\n",
    "  TN.update_state(y_true, y_pred)\n",
    "  FP.update_state(y_true, y_pred)\n",
    "  FN.update_state(y_true, y_pred)\n",
    "  return TP.result().numpy(),  TN.result().numpy(),  FP.result().numpy(), FN.result().numpy() \n",
    "\n",
    "# Подсчет метрик\n",
    "def calc_metrics(t, p, flag = 0): # t - y_true, p - y_pred\n",
    "  y_true=np.argmax(t, axis=1)\n",
    "  y_pred=np.argmax(p, axis=1)\n",
    "  beta = 2\n",
    "\n",
    "  f2_score = fbeta_score(y_true, y_pred, average='macro', beta=2)\n",
    "  precision = precision_score(y_true, y_pred, average='macro')\n",
    "  recall = recall_score(y_true, y_pred, average='macro')\n",
    "  TP, TN, FP, FN = tp_tn_fp_fn(t, p)\n",
    "  g2_score = TP/(TP+FP+beta*FN)\n",
    "\n",
    "  if flag == 0:\n",
    "    return f2_score, g2_score\n",
    "  elif flag == 1:\n",
    "    return f2_score, g2_score, precision, recall\n",
    "\n",
    "  #return f2_score, g2_score, AUC_sklearn\n",
    "\n",
    "# Таблица результатов\n",
    "table_res_ICBEB = pd.DataFrame(columns = ('AUC', 'F2', 'G2'))\n",
    "\n",
    "# Занесение новых результатов в таблицу\n",
    "def edit_table(table, model, X, y, index_name): # X - X_test, y - y_test \n",
    "  score = model.evaluate(X, y)\n",
    "  y_pr = model.predict(X) # y_pr - y_test_pred\n",
    "  f2_score, g2_score = calc_metrics(y, y_pr, flag = 0)\n",
    "  list_metrics = [f2_score, g2_score, score[1]]\n",
    "  table.loc[index_name] = list_metrics\n",
    "  return table\n",
    "\n",
    "# График loss и accuracy\n",
    "def plot_loss_and_accuracy_curves(_history):\n",
    "  fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(18,6))\n",
    "  axs[0].plot(_history.history['loss'], color='b', label='Training loss')\n",
    "  axs[0].plot(_history.history['val_loss'], color='r', label='Validation loss')\n",
    "  axs[0].set_title(\"Loss curves\")\n",
    "  axs[0].legend(loc='best', shadow=True)\n",
    "  axs[1].plot(_history.history['auc'], color='b', label='Training accuracy')\n",
    "  axs[1].plot(_history.history['val_auc'], color='r', label='Validation accuracy')\n",
    "  axs[1].set_title(\"Accuracy curves\")\n",
    "  axs[1].legend(loc='best', shadow=True)\n",
    "  plt.show()\n",
    "\n",
    "# Работа с моделями lstm и lstm_bidir\n",
    "def type_comp_fit_save_model_score(table, X_train, y_train, X_test, y_test, type_model, save_name, index_model_task):\n",
    "  # Уточняю количество классов\n",
    "  num_classes = y_train.shape[1]\n",
    "\n",
    "  # Выбор архитектуры модели\n",
    "  if type_model == 'lstm':\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(input_shape=(1000, 12), units=256,\n",
    "                   return_sequences=True,\n",
    "                   stateful=False, unroll=False\n",
    "    ))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.LSTM(units=256,\n",
    "                   return_sequences=False,\n",
    "                   stateful=False, unroll=False\n",
    "    ))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
    "    print(model.summary())\n",
    "\n",
    "    # Реализация раннего прекращения.\n",
    "    checkpoint_filepath = './checkpoint_lstm/'\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                          save_weights_only=True,\n",
    "                                                          save_best_only=True)\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=15,\n",
    "                                                  restore_best_weights=True)\n",
    "  elif type_model == 'lstm_bidir':\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Bidirectional(layers.LSTM(input_shape=(1000, 12), units=256,\n",
    "                         return_sequences=True,\n",
    "                         stateful=False, unroll=False\n",
    "                         )))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Bidirectional(layers.LSTM(units=256,\n",
    "                         return_sequences=False,\n",
    "                         stateful=False, unroll=False\n",
    "                         )))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "    model.build(input_shape = (None, 1000, 12)) # `input_shape` is the shape of the input data\n",
    "    print(model.summary())\n",
    "\n",
    "    # Реализация раннего прекращения.\n",
    "    checkpoint_filepath = './checkpoint_lstm_bidir/'\n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                          save_weights_only=True,\n",
    "                                                          save_best_only=True)\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=15,\n",
    "                                                  restore_best_weights=True)\n",
    "  \n",
    "  # Обучение\n",
    "  History = compile_fit(model, X_train, y_train, validation_split=0.1 ,early_stopping=early_stopping, model_checkpoint=model_checkpoint)\n",
    "\n",
    "  # Сохранение модели\n",
    "  model.save_weights(save_name)\n",
    "\n",
    "  # Построение графика\n",
    "  plot_loss_and_accuracy_curves(History)\n",
    "\n",
    "  # Сохранение в таблицу\n",
    "  table = edit_table(table, model, X_test, y_test, index_model_task)\n",
    "  return table\n",
    "                        \n",
    "tf.random.set_seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_L1RWaxDs-H"
   },
   "source": [
    "# Работа с lstm и lstm_bidir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfb0C181sAG_"
   },
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "ZjaZ-GYeYo-N",
    "outputId": "ce2328ea-2a62-41f7-a3d8-77bf7a9d0673"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'diag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm', 'lstm_diag.h5', 'lstm_diag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeUp4i-UsC_A"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'superdiag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm', 'lstm_superdiag.h5', 'lstm_superdiag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBkiGvQXsC7z"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'subdiag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm', 'lstm_subdiag.h5', 'lstm_subdiag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0BgkYPEsC3R"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'rhythm')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm', 'lstm_rhythm.h5', 'lstm_rhythm')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xGZcMq_sCwz"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'form')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm', 'lstm_diag.h5', 'lstm_form')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvwsl4CtMPUg"
   },
   "source": [
    "### lstm_bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJue5-TvMQkj"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'diag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm_bidir', 'lstm_bidir_diag.h5', 'lstm_bidir_diag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCrlI6S9sSYd"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'superdiag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm_bidir', 'lstm_bidir_superdiag.h5', 'lstm_bidir_superdiag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQdsFsM8sSSc"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'subdiag')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm_bidir', 'lstm_bidir_subdiag.h5', 'lstm_bidir_subdiag')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj3DShapsSNQ"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'rhytm')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm_bidir', 'lstm_bidir_rhytm.h5', 'lstm_bidir_rhytm')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5dvZ56MsSHU"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_ICBEB(task = 'form')\n",
    "table_res_ICBEB = type_comp_fit_save_model_score(table_res_ICBEB, X_train, y_train, X_test, y_test, 'lstm_bidir', 'lstm_bidir_form.h5', 'lstm_bidir_form')\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FSybICzsNCT"
   },
   "source": [
    "### Сохранение результатов в формат .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KLKHNsAZq7V-"
   },
   "outputs": [],
   "source": [
    "table_res_ICBEB.to_csv('table_res_ICBEB.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7def36fe8bd5fec4bb5af778b23511c8ac7b24717e5ef7201919a5b3f553865a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
